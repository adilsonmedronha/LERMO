{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 236328/236328 [2:46:52<00:00, 23.60it/s]  \n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "\n",
    "generate_keypoints(\"/media/SSD/DATASETS/LERMO/images/Andressa_R_dns_aug\",\n",
    "                   \"../data/\", \"Andressa_R_dns_aug.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import * \n",
    "\n",
    "def generate_keypoints(folder_path, output_dir, csv_name):\n",
    "    import re\n",
    "    csv_path = os.path.join(output_dir, csv_name)\n",
    "    hands = mp.solutions.hands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.5)\n",
    "    data_list = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for i, filename in enumerate(tqdm(files)):\n",
    "            path_to_loadimg = os.path.join(root, filename)\n",
    "            file_class = filename.split(\"_\")[0]\n",
    "            if path_to_loadimg[-4:] not in [\".png\", \".jpg\"]:\n",
    "                continue\n",
    "            image = cv2.imread(path_to_loadimg)\n",
    "            image_height, image_width, _ = image.shape\n",
    "            results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "            \n",
    "            if not results.multi_hand_landmarks: \n",
    "                os.remove(path_to_loadimg)\n",
    "                continue\n",
    "\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                x_i = [[min(int(landmark.x * image_width), image_width - 1), \n",
    "                        min(int(landmark.y * image_height), image_height - 1)] for landmark in hand_landmarks.landmark]\n",
    "                mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS, mp_drawing_styles.get_default_hand_landmarks_style(), mp_drawing_styles.get_default_hand_connections_style())\n",
    "                x_i_normalized = pre_process_landmark(x_i) \n",
    "                data_list.append([*x_i_normalized, file_class, path_to_loadimg])\n",
    "            \n",
    "            save_image_landmark = os.path.join(output_dir, \"images\", file_class)\n",
    "            if not os.path.exists(save_image_landmark):\n",
    "                os.makedirs(save_image_landmark)\n",
    "            cv2.imwrite(os.path.join(save_image_landmark, f\"{i}_{file_class}.png\"), image)\n",
    "            \n",
    "    xy = [\"x\", \"y\"]\n",
    "    df = pd.DataFrame(data_list, columns=[*[f'{i // 2}{xy[i % 2]}' for i in range(42)], 'Label', \"File_Path\"])\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    hands.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12826.62it/s]\n",
      " 42%|████▏     | 187/450 [00:20<00:28,  9.24it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m generate_keypoints(\u001b[39m\"\u001b[39;49m\u001b[39m/media/SSD/DATASETS/LERMO/images/Adilson_L_dns\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m../data/\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mAdilson_L_dns_refazendo.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[34], line 16\u001b[0m, in \u001b[0;36mgenerate_keypoints\u001b[0;34m(folder_path, output_dir, csv_name)\u001b[0m\n\u001b[1;32m     14\u001b[0m image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(path_to_loadimg)\n\u001b[1;32m     15\u001b[0m image_height, image_width, _ \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39mshape\n\u001b[0;32m---> 16\u001b[0m results \u001b[39m=\u001b[39m hands\u001b[39m.\u001b[39;49mprocess(cv2\u001b[39m.\u001b[39;49mcvtColor(image, cv2\u001b[39m.\u001b[39;49mCOLOR_BGR2RGB))\n\u001b[1;32m     18\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m results\u001b[39m.\u001b[39mmulti_hand_landmarks: \n\u001b[1;32m     19\u001b[0m     os\u001b[39m.\u001b[39mremove(path_to_loadimg)\n",
      "File \u001b[0;32m~/miniconda3/envs/tudo/lib/python3.10/site-packages/mediapipe/python/solutions/hands.py:153\u001b[0m, in \u001b[0;36mHands.process\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess\u001b[39m(\u001b[39mself\u001b[39m, image: np\u001b[39m.\u001b[39mndarray) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NamedTuple:\n\u001b[1;32m    133\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Processes an RGB image and returns the hand landmarks and handedness of each detected hand.\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \n\u001b[1;32m    135\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[39m         right hand) of the detected hand.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mprocess(input_data\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mimage\u001b[39;49m\u001b[39m'\u001b[39;49m: image})\n",
      "File \u001b[0;32m~/miniconda3/envs/tudo/lib/python3.10/site-packages/mediapipe/python/solution_base.py:365\u001b[0m, in \u001b[0;36mSolutionBase.process\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m    359\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    360\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph\u001b[39m.\u001b[39madd_packet_to_input_stream(\n\u001b[1;32m    361\u001b[0m         stream\u001b[39m=\u001b[39mstream_name,\n\u001b[1;32m    362\u001b[0m         packet\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_packet(input_stream_type,\n\u001b[1;32m    363\u001b[0m                                  data)\u001b[39m.\u001b[39mat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_simulated_timestamp))\n\u001b[0;32m--> 365\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_graph\u001b[39m.\u001b[39;49mwait_until_idle()\n\u001b[1;32m    366\u001b[0m \u001b[39m# Create a NamedTuple object where the field names are mapping to the graph\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[39m# output stream names.\u001b[39;00m\n\u001b[1;32m    368\u001b[0m solution_outputs \u001b[39m=\u001b[39m collections\u001b[39m.\u001b[39mnamedtuple(\n\u001b[1;32m    369\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mSolutionOutputs\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_stream_type_info\u001b[39m.\u001b[39mkeys())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "generate_keypoints(\"/media/SSD/DATASETS/LERMO/images/Adilson_L_dns\", \"../data/\", \"Adilson_L_dns_refazendo.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tudo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
